# -*- coding: utf-8 -*-
"""IP Fusion Layer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10IMjfsnWxWkaxPm3p0ervf8C7pOYS6Ee

# Heatmap
"""

#correlation
def corr_heatmap(df):
  corr = df.corr()
  plt.figure(figsize=(w,h))
  caxes = plt.matshow(corr,fignum=1)
  plt.xticks(range(len(corr.columns)),corr.columns,rotation=90)
  plt.yticks(range(len(corr.columns)),corr.columns)
  plt.colorbar(caxes)
  plt.show()

"""# Handle Outliers """

# Box Plot

fig,ax = plt.subplots(4,3,figsize=(20,20))
for i,j in zip(numerical_columns,ax.flatten()):
    sns.boxplot(df_new[i],ax=j)
    j.set_title(i)

# Using interquartile range to find outliers and remove them
for col in numerical_columns:
    q1 = df_new[col].quantile(0.25)
    q3 = df_new[col].quantile(0.75)
    iqr = q3-q1
    lower_bound = q1 - (1.5*iqr)
    upper_bound = q3 + (1.5*iqr)
    df_new = df_new[(df_new[col]>lower_bound) & (df_new[col]<upper_bound)]
print(df_new.shape)

"""# Just under or over sampling"""

#oversampling the minority class and undersampling the majority class to have same number of data

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42,sampling_strategy="minority")
X = df.drop("default.payment.next.month", axis=1)
y = df["default.payment.next.month"]
X_res, y_res = sm.fit_resample(X, y)

#checking the ratio of 0 and 1
y_res.value_counts()/len(y_res)

"""# Equal Sampling """

from collections import Counter
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split

print(y.value_counts()/len(y))

over = RandomOverSampler(sampling_strategy=0.6)
under = RandomUnderSampler(sampling_strategy=1.0)

X_over, y_over = over.fit_resample(X, y)
print(y_over.value_counts()/len(y_over))

X_res, y_res = under.fit_resample(X_over, y_over)
y_res.value_counts()/len(y_res)

"""# Isin"""

df.columns[df.isin(["-1"]).any()]

"""# 2 linear classification"""

def l_regression(X_train, X_test, y_train, y_test):
    model =LogisticRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("Logistic regression recall: ", recall_score(y_test, y_pred))
    print("Logistic regression precision: ", precision_score(y_test, y_pred))
    #f1 score
    print("Logistic regression F1 score: ", f1_score(y_test, y_pred))
    #classification error
    print("Logistic regression Classification error: ", 1 - accuracy_score(y_test, y_pred))
    #spedificity
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    specificity = tn / (tn+fp)
    print("Logistic regression Specificity: ", specificity)
    print("Logistic regression AUC: ", roc_auc_score(y_test, y_pred))
    print("Logistic regression Accuracy: ", accuracy_score(y_test, y_pred))
    plot_confustion_matrix(y_test,y_pred)
    
    return model

def naive_bayes(X_train, X_test, y_train, y_test):
    model = GaussianNB()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print("Naive Bayes recall: ", recall_score(y_test, y_pred))
    print("Naive Bayes precision: ", precision_score(y_test, y_pred))
    #f1 score
    print("Naive Bayes F1 score: ", f1_score(y_test, y_pred))
    #classification error
    print("Naive Bayes Classification error: ", 1 - accuracy_score(y_test, y_pred))
    #spedificity
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    specificity = tn / (tn+fp)
    print("Naive Bayes Specificity: ", specificity)
    print("Logistic regression AUC: ", roc_auc_score(y_test, y_pred))
    print("Logistic regression Accuracy: ", accuracy_score(y_test, y_pred))
    plot_confustion_matrix(y_test,y_pred)
    
    return model

"""# Confusion Matrix"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confustion_matrix(y_test,y_pred):
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d")
    plt.title("Confusion Matrix")
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.show()

"""# CV"""

#kfold cross validation for logistic regression and naive bayes
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict

#kfold cross validation for logistic regression
kfold = KFold(n_splits=10)
lmodelCV = LogisticRegression()
scoring = 'accuracy'
results = cross_val_score(lmodelCV, X_res, y_res, cv=kfold, scoring=scoring)
print("10-fold cross validation average accuracy: %.3f" % (results.mean()))

"""# Hypertuning"""

# optimize the model using grid search
from sklearn.model_selection import GridSearchCV

# logistic regression
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}
grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)
grid.fit(Xl_train, yl_train)

# print best parameter after tuning
print(grid.best_params_)

print(grid.best_estimator_)

y_pred = grid.predict(Xl_test)

# naive bayes grid search
param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]}
#DT
params = {"criterion":['gini','entropy'],
          "max_depth":range(3,8),
          "max_leaf_nodes":range(2,8)}

#SVM
params = {"C":[0.01,0.1,1,10]}

#gridsearch for mlpclassifier
params = {"hidden_layer_sizes": [(100,),(100,100),(100,100,100)],
            "activation":['identity','logistic','tanh','relu'],
            "solver":['lbfgs','sgd','adam'],
            "alpha":[0.0001,0.001,0.01,0.1,1],
            "learning_rate":['constant','invscaling','adaptive']}
grid = GridSearchCV(mlp,params,cv=5)
grid.fit(X_train,y_train)
print(grid.best_params_)
print(grid.best_score_)
print(grid.best_estimator_)
#train model with best parameters
mlp = MLPClassifier(activation='tanh',alpha=0.0001,hidden_layer_sizes=(100,100,100),learning_rate='constant',solver='lbfgs')

"""# Optimal Threshold"""

# adjust the threshold for logistic regression model using ROC and AUC
y_pred_prob = lmodel.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print(optimal_threshold)
#mark the optimal threshold on the ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label='Logistic Regression')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Logistic Regression ROC Curve')
plt.plot(fpr[optimal_idx], tpr[optimal_idx], marker='o', markersize=5, color="red")

plt.show()

# find optimal threshold
y_pred = np.where(lmodel.predict_proba(X_test)[:,1] > optimal_threshold, 1, 0)
print("Logistic regression recall: ", recall_score(y_test, y_pred))
print("Logistic regression precision: ", precision_score(y_test, y_pred))
#f1 score
print("Logistic regression F1 score: ", f1_score(y_test, y_pred))
#classification error
print("Logistic regression Classification error: ", 1 - accuracy_score(y_test, y_pred))
#spedificity
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
specificity = tn / (tn+fp)
print("Logistic regression Specificity: ", specificity)
plot_confustion_matrix(y_test,y_pred)

#make the data size smaller using sampling in a another dataframe

df1 = df.sample(frac=0.1, replace=True, random_state=1)
print(df1.shape, df.shape)

"""# Scatterplot"""

import seaborn as sns
sns.regplot(x=y_test, y=preds, data=df, scatter_kws={"color": "blue"}, line_kws={"color": "red"})
plt.show()

"""# Feature selection with correlation matrix"""

corr = df.corr()
rel = {}
#take features that are highly correlated with the target
corr_target = abs(corr["AveragePrice"])
threshold = [0.25,0.35,0.5]
for i in threshold:
    # print(i)
    relevant_positive_features = corr_target[corr_target>i]
    relevant_negative_features = corr_target[corr_target<-1*i]
    rel[i] = relevant_negative_features.append(relevant_positive_features)

print(rel)

col1 = rel[0.25].index
df1 = df[col1]
corr_heatmap(df1)

"""# Linear Reg Accuracy"""

#linear regression accuracy
errors1 = abs(preds1 - y1_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors1), 2), 'degrees.')
# Calculate mean absolute percentage error (MAPE)
mape1 = 100 * (errors1 / y1_test)
# Calculate and display accuracy
accuracy1 = 100 - np.mean(mape1)
print('Accuracy:', round(accuracy1, 2), '%.')

"""# PCA"""

#pca 
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(df_std)
df_pca = pd.DataFrame(pca.transform(df_std))
df_pca.shape

"""# Elbow"""

cs=[]
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
    kmeans.fit(df_pca)
    cs.append(kmeans.inertia_)
plt.plot(range(1, 11), cs)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('CS')
plt.show()

"""# Predict and Plot"""

kmeans = KMeans(n_clusters=4)
y = kmeans.fit_predict(df_pca)

plt.figure(figsize=(10,10))
plt.scatter(df_pca.iloc[y==0,0],df_pca.iloc[y==0,1],c="red",label="cluster1")
plt.scatter(df_pca.iloc[y==1,0],df_pca.iloc[y==1,1],c="blue",label="cluster2")
plt.scatter(df_pca.iloc[y==2,0],df_pca.iloc[y==2,1],c="green",label="cluster3")
plt.scatter(df_pca.iloc[y==3,0],df_pca.iloc[y==3,1],c="black",label="cluster4")
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],c="yellow",label="centroid")
plt.xlabel("pca1")
plt.ylabel("pca2")
plt.legend()
plt.show()

"""# Dendrogram Cut"""

# heirachical clustering
from scipy.cluster.hierarchy import linkage, dendrogram 
"""Dendrogram is a tree diagram that records the sequences of merges or splits in a hierarchical clustering.
It is used to find the optimal number of clusters in the data."""
plt.figure(figsize=(20, 20)) 
merg = linkage(df_std, method = "ward") # ward method is used to minimize the variance within each cluster
dendrogram(merg, leaf_rotation = 90) # leaf_rotation is used to rotate the x-axis labels
plt.xlabel("data points")
plt.ylabel("euclidean distances")
plt.show()

"""# Agglomerative """

from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage = 'ward')
y_hc = hc.fit_predict(df_std)

